<!DOCTYPE html>
<html>
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Louis Bradshaw</title>
        <link href="https://fonts.googleapis.com/css?family=Lato:400,700&display=swap" rel="stylesheet">
        <style>
            body { 
                max-width: 650px;
                line-height: 1.2;
                font-size: 16px;
                margin: 0 auto;
            }
            #main {
                margin-left: 10px;
                margin-right: 10px;
                margin-top: 40px;
                margin-bottom: 40px;
            }
            p, li {
                overflow-wrap: break-word;
                word-wrap: break-word;
                hyphens: auto;
                text-align: justify;
            }
            li {
            margin-bottom: 10px; /* Add space between list items */
            }
            li:last-child {
                margin-bottom: 0; /* Remove margin from the last item */
            }
            p {
                margin-top: 0.5em;
                margin-bottom: 0.5em;
            }
            h4 {
                margin-top: 2em; 
            }
            figcaption {
                color: grey;
                margin-bottom: 10px; /* Add space after the subtitle */
            }
            .email-reverse {
                unicode-bidi: bidi-override;
                direction: rtl;
            }
            a {
                text-decoration: none;
            }
            a:focus, a:hover {
                color: #f09228;
                text-decoration: none;
            }
        </style>

    </head>
    <body>
        <div id="main">
            <h3>Louis Bradshaw</h3>
            <h5><a href="https://drive.google.com/file/d/1RMEZFuwBYVqbBX65mDDIvrIq1lT1xr-K/view?usp=sharing">Curriculum Vitae</a> 
                / <a href="https://scholar.google.com/citations?user=0VLMIk8AAAAJ">Google Scholar</a> 
                / <a href="https://github.com/loubbrad">GitHub</a> 
                / <a href="https://twitter.com/loubbrad">Twitter</a>
                <br><span>l.b.bradshaw [at] qmul.ac.uk</span></h5>

            <p>I'm a CS/ML PhD student at <a href="https://www.c4dm.eecs.qmul.ac.uk/">C4DM</a>, where I specialize in Deep Learning for Audio. 
                Prior to my PhD, I studied Mathematics (Algebraic Geometry) at Imperial College London (BSc, MSc). My current research interests are varied and include:
            </p>
            <p><b>Deep Learning for Music</b>. I've led research projects in several core areas of generative music and information retrieval including: musical foundation models 
            (see the <a href="https://github.com/EleutherAI/aria">Aria</a> project), self-supervised representation learning, audio transcription (see <a href="https://github.com/EleutherAI/aria-amt">Aria-AMT</a>), and datasets (see <a href="https://huggingface.co/datasets/loubb/aria-midi">Aria-MIDI</a>). 
            My research has broadly focused on improving symbolic generative models for piano performance, with the aim of creating real-time interactive systems that enable human-AI co-creation.
            
            <p><b>Hybrid Audio/Language Models</b>. I've developed a growing research interest in models that integrate audio with text or other token-based symbolic information.
                This includes areas such as neural audio codecs, automatic speech recognition, and audio-language models. I'm particularly interested in improving conversational 
                speech foundation models (e.g., Moshi) through both architectural and data-centric approaches.</p>
            <p>
                I'm also extremely interested in the engineering problems surrounding ML/DL. In my non-research time, I currently dedicate a portion to studying C++/CUDA.
                Outside of research, I have a deep love for mathematics, music production, and reading. The best part of doing a PhD is getting to learn 
                from all kinds of people. If you are interested in collaborating, or just chatting about research, feel free to reach out!
            </p>
        
            <h4>News</h4>
            <ul style="list-style-type: none; padding-left: 0;">
                <li>
                <b>[Nov 2025]</b> I started an internship at Sony in Tokyo, focusing on multimodal models for audio/music generation and understanding.
                </li> 
                <li>
                <b>[Sep 2025]</b> I'll be presenting our work on real-time, interactive generative music systems: <a href="https://arxiv.org/abs/2511.01663"><i>The Ghost in the Keys</i></a> at NeurIPS 2025, as well as at the AI4Music workshop.
                </li> 
                <li>
                <b>[Jun 2025]</b> Our paper <a href="https://arxiv.org/abs/2506.23869">Scaling Self-Supervised Representation Learning for Symbolic Piano Performance</a> was accepted to ISMIR 2025. 
                </li> 
                <li>
                <b>[Jan 2025]</b> Our paper <a href="https://openreview.net/forum?id=X5hrhgndxW">Aria-MIDI: A Dataset of Piano MIDI Files</a> was accepted to ICLR 2025.
                </li> 
                <li>
                <b>[Jan 2024]</b> Thanks to StabilityAI and EleutherAI, who have provided us with significant compute sponsorship (10k A100 hours) for the Aria project.
                </li>
            </ul>

            <h4>Aria Project</h4>

            <div align="center">
                <p>The Aria project was a project to scale transformer-based foundation models for symbolic music. The project 
                    got its codename, <i>Aria</i>, from the <a href="https://www.youtube.com/watch?v=p4yAB37wG5s">Goldberg Variations</a>, and has
                    attracted generous compute support from EleutherAI & StabilityAI. The code and publications for our model can be
                    found on the official <a href="https://github.com/EleutherAI/aria">repository</a>.
            <div>
              <figure style="text-align:center;display:inline-block">
               <figcaption>
                Conditioned on the initial theme
               </figcaption>
               <audio controls=""><source src="assets/aria-mp3/original.mp3" type="audio/mpeg" /></audio>
              </figure>
              <figure style="text-align:center;display:inline-block">
               <figcaption>
                Jazz ballade interpretation of <i>Misty</i>
               </figcaption>
               <audio controls=""><source src="assets/aria-mp3/misty.mp3" type="audio/mpeg" /></audio>
              </figure>
              <figure style="text-align:center;display:inline-block">
               <figcaption>
                Jazz in the style of Bill Evans
               </figcaption>
               <audio controls=""><source src="assets/aria-mp3/evans.mp3" type="audio/mpeg" /></audio>
              </figure>
            </div>
                
            <p>If you are interested in finding out more about the Aria project, the best place is on the EleutherAI <a href="https://discord.com/invite/zBGx3azzUn">discord channel</a>.</p>

            </div>
            
            <h4>Misc</h4>
                
            <p>These essays 
                [<a href="https://www.cs.virginia.edu/~robins/YouAndYourResearch.html">1</a>, 
                <a href="https://www.arvindguptatoys.com/arvindgupta/mathsapology-hardy.pdf">2</a>] 
                and these books
                [<a href="https://en.wikipedia.org/wiki/Cannery_Row_(novel)">3</a>, 
                <a href="https://en.wikipedia.org/wiki/Crime_and_Punishment">4</a>, 
                <a href="https://en.wikipedia.org/wiki/Surely_You%27re_Joking,_Mr._Feynman!">5</a>] 
                had a big influence on me.</p>
        </div>
    </body>
</html>
